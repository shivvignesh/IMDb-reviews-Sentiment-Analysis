{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('dataset.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>first think another Disney movie, might good, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>big fan Stephen King's work, film made even gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       SentimentText  Sentiment\n",
       "0  first think another Disney movie, might good, ...          1\n",
       "1  Put aside Dr. House repeat missed, Desperate H...          0\n",
       "2  big fan Stephen King's work, film made even gr...          1\n",
       "3  watched horrid thing TV. Needless say one movi...          0\n",
       "4  truly enjoyed film. acting terrific plot. Jeff...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_text,pattern):\n",
    "  r=re.findall(pattern,input_text)\n",
    "  for i in r:\n",
    "    input_text=re.sub(i,'',input_text)\n",
    "    \n",
    "  return input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tidy']=np.vectorize(remove_pattern)(data['SentimentText'],',[\\w]*')\n",
    "data['tidy']=data['tidy'].str.replace('[^a-zA-z]',\" \")\n",
    "data['tidy']=data['tidy'].apply(lambda x:' '.join([w for w in x.split() if len(w)>2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>tidy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>first think another Disney movie, might good, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>first think another Disney movie might good ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
       "      <td>0</td>\n",
       "      <td>Put aside House repeat missed Desperate Housew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>big fan Stephen King's work, film made even gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>big fan Stephen King work film made even great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
       "      <td>0</td>\n",
       "      <td>watched horrid thing Needless say one movies w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
       "      <td>1</td>\n",
       "      <td>truly enjoyed film acting terrific plot Jeff C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       SentimentText  Sentiment  \\\n",
       "0  first think another Disney movie, might good, ...          1   \n",
       "1  Put aside Dr. House repeat missed, Desperate H...          0   \n",
       "2  big fan Stephen King's work, film made even gr...          1   \n",
       "3  watched horrid thing TV. Needless say one movi...          0   \n",
       "4  truly enjoyed film. acting terrific plot. Jeff...          1   \n",
       "\n",
       "                                                tidy  \n",
       "0  first think another Disney movie might good ki...  \n",
       "1  Put aside House repeat missed Desperate Housew...  \n",
       "2  big fan Stephen King work film made even great...  \n",
       "3  watched horrid thing Needless say one movies w...  \n",
       "4  truly enjoyed film acting terrific plot Jeff C...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [first, think, another, Disney, movie, might, ...\n",
       "1    [Put, aside, House, repeat, missed, Desperate,...\n",
       "2    [big, fan, Stephen, King, work, film, made, ev...\n",
       "3    [watched, horrid, thing, Needless, say, one, m...\n",
       "4    [truly, enjoyed, film, acting, terrific, plot,...\n",
       "Name: tidy, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_review=data['tidy'].apply(lambda x:x.split())\n",
    "tokenized_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_review=tokenized_review.apply(lambda x:[stemmer.stem(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [first, think, anoth, disney, movi, might, goo...\n",
       "1    [put, asid, hous, repeat, miss, desper, housew...\n",
       "2    [big, fan, stephen, king, work, film, made, ev...\n",
       "3    [watch, horrid, thing, needless, say, one, mov...\n",
       "4    [truli, enjoy, film, act, terrif, plot, jeff, ...\n",
       "Name: tidy, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokenized_review)):\n",
    "    tokenized_review[i]=' '.join(tokenized_review[i])\n",
    "\n",
    "data['tidy']=tokenized_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>tidy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>first think another Disney movie, might good, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>first think anoth disney movi might good kid m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
       "      <td>0</td>\n",
       "      <td>put asid hous repeat miss desper housew new wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>big fan Stephen King's work, film made even gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>big fan stephen king work film made even great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
       "      <td>0</td>\n",
       "      <td>watch horrid thing needless say one movi watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
       "      <td>1</td>\n",
       "      <td>truli enjoy film act terrif plot jeff comb tal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       SentimentText  Sentiment  \\\n",
       "0  first think another Disney movie, might good, ...          1   \n",
       "1  Put aside Dr. House repeat missed, Desperate H...          0   \n",
       "2  big fan Stephen King's work, film made even gr...          1   \n",
       "3  watched horrid thing TV. Needless say one movi...          0   \n",
       "4  truly enjoyed film. acting terrific plot. Jeff...          1   \n",
       "\n",
       "                                                tidy  \n",
       "0  first think anoth disney movi might good kid m...  \n",
       "1  put asid hous repeat miss desper housew new wa...  \n",
       "2  big fan stephen king work film made even great...  \n",
       "3  watch horrid thing needless say one movi watch...  \n",
       "4  truli enjoy film act terrif plot jeff comb tal...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words=' '.join([word for word in data['tidy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_list=all_words.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_word_frame=pd.DataFrame(all_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=all_word_frame[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movi           51690\n",
       "film           48181\n",
       "one            27728\n",
       "like           22778\n",
       "time           16188\n",
       "good           15353\n",
       "make           15205\n",
       "the            14265\n",
       "charact        14178\n",
       "get            14139\n",
       "see            14109\n",
       "watch          13942\n",
       "stori          13165\n",
       "even           12897\n",
       "would          12434\n",
       "realli         11731\n",
       "well           11024\n",
       "scene          10595\n",
       "look           10042\n",
       "show            9875\n",
       "much            9760\n",
       "end             9651\n",
       "peopl           9389\n",
       "bad             9338\n",
       "great           9164\n",
       "also            9153\n",
       "first           9060\n",
       "love            9013\n",
       "think           8910\n",
       "don             8847\n",
       "               ...  \n",
       "sequen             1\n",
       "moimem             1\n",
       "emptour            1\n",
       "stiletto           1\n",
       "lawprovid          1\n",
       "tenebra            1\n",
       "yaniss             1\n",
       "befallen           1\n",
       "thanklessli        1\n",
       "lahem              1\n",
       "cluni              1\n",
       "kimber             1\n",
       "quatier            1\n",
       "whord              1\n",
       "kiesser            1\n",
       "motormouth         1\n",
       "bahiyyaji          1\n",
       "loveto             1\n",
       "lonestar           1\n",
       "leroi              1\n",
       "meola              1\n",
       "doggish            1\n",
       "dvice              1\n",
       "rabbitt            1\n",
       "flagwav            1\n",
       "labeija            1\n",
       "pando              1\n",
       "pyasa              1\n",
       "driftwood          1\n",
       "fufu               1\n",
       "Name: 0, Length: 51292, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(np.array(all_words.split(' ')).reshape(-1, 1), columns=['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = list(df2['words'].str.split(' ', expand=True).stack().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51292"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = list(df2['words'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame(np.hstack((np.array(unique_words).reshape(-1,1),np.array(word_counts).reshape(-1,1))), columns=['words','word_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_new=df4[df4['word_count'].map(len)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_words_list = list(df4_new['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words=list(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in df4_words_list:\n",
    "    unique_words.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14132"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14132</th>\n",
       "      <td>contemptu</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14133</th>\n",
       "      <td>bicycl</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14134</th>\n",
       "      <td>victrola</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14135</th>\n",
       "      <td>vaccin</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14136</th>\n",
       "      <td>barcelona</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words word_count\n",
       "14132  contemptu          9\n",
       "14133     bicycl          9\n",
       "14134   victrola          9\n",
       "14135     vaccin          9\n",
       "14136  barcelona          9"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>tidy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>first think another Disney movie, might good, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>first think anoth disney movi might good kid m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
       "      <td>0</td>\n",
       "      <td>put asid hous repeat miss desper housew new wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>big fan Stephen King's work, film made even gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>big fan stephen king work film made even great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
       "      <td>0</td>\n",
       "      <td>watch horrid thing needless say one movi watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
       "      <td>1</td>\n",
       "      <td>truli enjoy film act terrif plot jeff comb tal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       SentimentText  Sentiment  \\\n",
       "0  first think another Disney movie, might good, ...          1   \n",
       "1  Put aside Dr. House repeat missed, Desperate H...          0   \n",
       "2  big fan Stephen King's work, film made even gr...          1   \n",
       "3  watched horrid thing TV. Needless say one movi...          0   \n",
       "4  truly enjoyed film. acting terrific plot. Jeff...          1   \n",
       "\n",
       "                                                tidy  \n",
       "0  first think anoth disney movi might good kid m...  \n",
       "1  put asid hous repeat miss desper housew new wa...  \n",
       "2  big fan stephen king work film made even great...  \n",
       "3  watch horrid thing needless say one movi watch...  \n",
       "4  truli enjoy film act terrif plot jeff comb tal...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [first, think, anoth, disney, movi, might, goo...\n",
       "1    [put, asid, hous, repeat, miss, desper, housew...\n",
       "2    [big, fan, stephen, king, work, film, made, ev...\n",
       "3    [watch, horrid, thing, needless, say, one, mov...\n",
       "4    [truli, enjoy, film, act, terrif, plot, jeff, ...\n",
       "Name: tidy, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tidy=new_data['tidy'].apply(lambda x:x.split())\n",
    "tokenized_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tokenized_tidy:\n",
    "    for j in i:\n",
    "        if j not in unique_words:\n",
    "            i.remove(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokenized_tidy)):\n",
    "    tokenized_tidy[i]=' '.join(tokenized_tidy[i])\n",
    "\n",
    "new_data['new_tidy']=tokenized_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>tidy</th>\n",
       "      <th>new_tidy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>first think another Disney movie, might good, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>first think anoth disney movi might good kid m...</td>\n",
       "      <td>first think anoth disney movi might good kid m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
       "      <td>0</td>\n",
       "      <td>put asid hous repeat miss desper housew new wa...</td>\n",
       "      <td>put asid hous repeat miss desper housew new wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>big fan Stephen King's work, film made even gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>big fan stephen king work film made even great...</td>\n",
       "      <td>big fan stephen king work film made even great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
       "      <td>0</td>\n",
       "      <td>watch horrid thing needless say one movi watch...</td>\n",
       "      <td>watch horrid thing needless say one movi watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
       "      <td>1</td>\n",
       "      <td>truli enjoy film act terrif plot jeff comb tal...</td>\n",
       "      <td>truli enjoy film act terrif plot jeff comb tal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       SentimentText  Sentiment  \\\n",
       "0  first think another Disney movie, might good, ...          1   \n",
       "1  Put aside Dr. House repeat missed, Desperate H...          0   \n",
       "2  big fan Stephen King's work, film made even gr...          1   \n",
       "3  watched horrid thing TV. Needless say one movi...          0   \n",
       "4  truly enjoyed film. acting terrific plot. Jeff...          1   \n",
       "\n",
       "                                                tidy  \\\n",
       "0  first think anoth disney movi might good kid m...   \n",
       "1  put asid hous repeat miss desper housew new wa...   \n",
       "2  big fan stephen king work film made even great...   \n",
       "3  watch horrid thing needless say one movi watch...   \n",
       "4  truli enjoy film act terrif plot jeff comb tal...   \n",
       "\n",
       "                                            new_tidy  \n",
       "0  first think anoth disney movi might good kid m...  \n",
       "1  put asid hous repeat miss desper housew new wa...  \n",
       "2  big fan stephen king work film made even great...  \n",
       "3  watch horrid thing needless say one movi watch...  \n",
       "4  truli enjoy film act terrif plot jeff comb tal...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_vectorizer=CountVectorizer(stop_words='english')\n",
    "rev= rev_vectorizer.fit_transform(new_data['new_tidy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rev=rev\n",
    "\n",
    "xtrain_rev,xvalid_rev,ytrain,yvalid=train_test_split(train_rev,new_data['Sentiment'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg=LogisticRegression()\n",
    "lreg.fit(xtrain_rev,ytrain)\n",
    "\n",
    "prediction = lreg.predict_proba(xvalid_rev) # predicting on the validation set\n",
    "prediction_int = prediction[:,1] >= 0.5 # if prediction is greater than or equal to 0.3 than 1 else 0\n",
    "prediction_int = prediction_int.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8654153354632588"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg.fit(xtrain_rev,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lreg.predict(xvalid_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8652\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(yvalid,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
